# From Models to Systems: A Comprehensive Survey of Efficient Multimodal Learning
The official GitHub page for the survey paper "From Models to Systems: A Comprehensive Survey of Efficient Multimodal Learning". And this paper is under review.


## Model
### Modality-specific Encoders
#### Vision Encoder
1. 2017_arXiv_Mobilenets: Efficient convolutional neural networks for mobile vision applications [arXiv](https://arxiv.org/abs/1704.04861)
2. 2018_CVPR_Shufflenet: An extremely efficient convolutional neural network for mobile devices [arXiv](https://arxiv.org/abs/1707.01083)
3. 2019_ICML_Efficientnet: Rethinking model scaling for convolutional neural networks [arXiv](https://arxiv.org/abs/1905.11946)
4. 2021_arXiv_Mobilevit: light-weight, general-purpose, and mobile-friendly vision transformer [arXiv](https://arxiv.org/abs/2110.02178)
5. 2021_NeurIPS_Coatnet: Marrying convolution and attention for all data sizes [arXiv](https://arxiv.org/abs/2106.04803)
6. 2022_CVPR_Metaformer is actually what you need for vision [arXiv](https://arxiv.org/abs/2111.11418)
7. 2020_arXiv_An image is worth 16x16 words: Transformers for image recognition at scale [arXiv](https://arxiv.org/abs/2010.11929)
8. 2021_ICCV_Swin transformer: Hierarchical vision transformer using shifted windows [arXiv](https://arxiv.org/abs/2103.14030)(https://openaccess.thecvf.com/content/ICCV2021/papers/Liu_Swin_Transformer_Hierarchical_Vision_Transformer_Using_Shifted_Windows_ICCV_2021_paper.pdf)
9. 2021_CVPR_Masked autoencoders are scalable vision learners [arXiv](https://arxiv.org/abs/2111.06377)
10. 2022_arXiv_Beit v2: Masked image modeling with vector-quantized visual tokenizers [arXiv](https://arxiv.org/abs/2208.06366)
11. 2023_COLM_Mamba: Linear-Time Sequence Modeling with Selective State Spaces [arXiv](https://arxiv.org/abs/2312.00752)
12. 2024_arXiv_Vision mamba: Efficient visual representation learning with bidirectional state space model [arXiv](https://arxiv.org/abs/2401.09417)
13. 2024_arXiv_Kan: Kolmogorov-arnold networks [arXiv](https://arxiv.org/abs/2404.19756)
14. 2021_ICLR_Learning transferable visual models from natural language supervision [arXiv](https://arxiv.org/abs/2103.00020)
15. 2021_ICLR_Scaling up visual and vision-language representation learning with noisy text supervision [arXiv](https://arxiv.org/abs/2102.05918)
16. 2023_ICCV_Sigmoid loss for language image pre-training [arXiv](https://arxiv.org/abs/2303.15343)
17. 2021_ICCV_Emerging properties in self-supervised vision transformers [arXiv](https://arxiv.org/abs/2104.14294)
18. 2023_arXiv_Dinov2: Learning robust visual features without supervision [arXiv](https://arxiv.org/abs/2304.07193)
19. 2025_arXiv_DINOv3 [arXiv](https://arxiv.org/abs/2508.10104)
### Unified Encoders
### Structural Sparsity
### Structural Decoding
### Modular Adaptation

## Algorithm
### Token Compression & Selective Computing
### Pruning
### Quantization
### Knowledge Distillation
### Prompting & Speculative Decoding
### Caching & Reuse
### Runtime Sparsity

## System
### KV Cache Management & Serving
### Edgeâ€“cloud Collaboration
### Latency-Aware Scheduling & Pipelining
### Hardware-software Co-design
### Federated Learning

## Application
### Affective Computing and Human Behavior Analysis
### Embodied AI & Robotics
### Media Understanding and Generation
### Healthcare and Biomedical Intelligence
### Spatial and Physical Scene Understanding
### Multimodal Reasoning
